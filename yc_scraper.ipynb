{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d9e2c-a78d-4e0b-83e4-6a02ed0a152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver  # For browser automation\n",
    "from selenium.webdriver.common.by import By  # To specify HTML element locating strategies\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # For waiting until certain conditions are met\n",
    "from selenium.webdriver.support import expected_conditions as EC  # To specify conditions for WebDriverWait\n",
    "import time  # For sleep and timestamp functionality\n",
    "import pandas as pd  # For handling Excel files and dataframes\n",
    "import random as rd  # For generating random delays\n",
    "from time import sleep  # Alternative for time.sleep\n",
    "from datetime import datetime  # For timestamp handling\n",
    "\n",
    "# Input file containing the list of company names\n",
    "input_file = \"company_name_list.xlsx\"  \n",
    "company_df = pd.read_excel(input_file)  # Read the Excel file into a DataFrame\n",
    "company_names = company_df[\"Company Name\"].tolist()  # Extract the list of company names\n",
    "\n",
    "# Base URL of the Y Combinator companies page\n",
    "base_url = \"https://www.ycombinator.com/companies\"\n",
    "\n",
    "# Initialize the Selenium WebDriver for Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()  # Maximize the browser window for better visibility\n",
    "\n",
    "# List to store the company names and their corresponding links\n",
    "company_links = []\n",
    "\n",
    "# Loop through each company name in the list\n",
    "for company in company_names:\n",
    "    print(f\"Searching for: {company}\")  # Print the company being searched\n",
    "    \n",
    "    driver.get(base_url)  # Navigate to the Y Combinator companies page\n",
    "    \n",
    "    try:\n",
    "        # Wait until the search box element is located, with a maximum wait time of 10 seconds\n",
    "        search_box = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='ycdc_new/pages/Companies/IndexPage-react-component-2152ffe0-d666-4e44-87fe-a0887c5ae3a9']/div[2]/section[2]/div/div[2]/div[2]/div[1]/input\"))\n",
    "        )\n",
    "        \n",
    "        # Clear the search box, type the company name, and submit the search\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(company)\n",
    "        search_box.submit()\n",
    "        \n",
    "        # Wait until the first search result appears and capture it\n",
    "        first_result = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[2]/section[2]/div/div[2]/div[2]/div[4]/a[1]/div/div[2]/div/div[1]/span[1]\"))\n",
    "        )\n",
    "        \n",
    "        # Get the link of the first result (if available)\n",
    "        link = first_result.get_attribute(\"href\")\n",
    "        company_links.append({\n",
    "            \"Company Name\": company,\n",
    "            \"Link\": link if link else \"No link found\"\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully and log the issue\n",
    "        print(f\"Error searching for {company}: {e}\")\n",
    "        company_links.append({\"Company Name\": company, \"Link\": \"Error or no result\"})\n",
    "    \n",
    "    # Add a random delay between requests\n",
    "    time.sleep(rd.randint(2, 5))\n",
    "\n",
    "# Save the results to an Excel file\n",
    "output_file = \"ycombinator_founder_links.xlsx\"\n",
    "pd.DataFrame(company_links).to_excel(output_file, index=False)  # Write the data to an Excel file without an index\n",
    "\n",
    "# Quit the WebDriver to close the browser session\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3c0ba-8f7f-4ca2-95e1-b86a72d5c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the profile data for all companies\n",
    "all_profile_data = []\n",
    "\n",
    "# Input file containing company URLs\n",
    "company_url_directory = \"ycombinator_founder_links.xlsx\"\n",
    "df = pd.read_excel(company_url_directory)  # Read the Excel file into a DataFrame\n",
    "\n",
    "# Initialize the Selenium WebDriver for Chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()  # Maximize the browser window\n",
    "\n",
    "# Loop through each unique URL in the dataframe\n",
    "for unique_url in df[\"Links\"]:\n",
    "    driver.get(unique_url)  # Navigate to the company's page\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "    # Initialize variables to store data with default empty values\n",
    "    try:\n",
    "        company_name = driver.find_element(By.XPATH, \"//h1\").text  # Extract company name\n",
    "    except:\n",
    "        company_name = \"\"  # Default to empty if not found\n",
    "\n",
    "    # Extract details for Person 1 (P1)\n",
    "    try:\n",
    "        p1_name = driver.find_element(By.XPATH, \n",
    "            \"//*[@id='ycdc_new/pages/Companies/ShowPage-react-component-caffd477-2eee-4501-aad0-9f3b5cea8622']/div[2]/div/section/div[2]/div[1]/div[2]/div/div/div[1]\").text\n",
    "    except:\n",
    "        p1_name = \"\"\n",
    "    try:\n",
    "        p1_x = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/div/section/div[2]/div[1]/div[2]/div/div/div[2]/a[1]\"\n",
    "            ).get_attribute(\"href\")  # Extract Twitter link\n",
    "    except:\n",
    "        p1_x = \"\"\n",
    "    try:\n",
    "        p1_linkedin = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/div/section/div[2]/div[1]/div[2]/div/div/div[2]/a[2]\"\n",
    "            ).get_attribute(\"href\")  # Extract LinkedIn link\n",
    "    except:\n",
    "        p1_linkedin = \"\"\n",
    "\n",
    "    # Extract details for Person 2 (P2)\n",
    "    try:\n",
    "        p2_name = driver.find_element(By.XPATH, \n",
    "            \"/html/body/div[1]/div[2]/div/section/div[2]/div[2]/div[2]/div/div/div[1]\").text\n",
    "    except:\n",
    "        p2_name = \"\"\n",
    "    try:\n",
    "        p2_x = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/div/section/div[2]/div[2]/div[2]/div/div/div[2]/a[1]\"\n",
    "            ).get_attribute(\"href\")  # Extract Twitter link\n",
    "    except:\n",
    "        p2_x = \"\"\n",
    "    try:\n",
    "        p2_linkedin = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/div/section/div[2]/div[2]/div[2]/div/div/div[2]/a[2]\"\n",
    "            ).get_attribute(\"href\")  # Extract LinkedIn link\n",
    "    except:\n",
    "        p2_linkedin = \"\"\n",
    "\n",
    "    # Extract details for Person 3 (P3)\n",
    "    try:\n",
    "        p3_name = driver.find_element(By.XPATH, \n",
    "            \"/html/body/div[1]/div[2]/div/section/div[2]/div[3]/div[2]/div/div/div[1]\").text\n",
    "    except:\n",
    "        p3_name = \"\"\n",
    "    try:\n",
    "        p3_x = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/div/section/div[2]/div[3]/div[2]/div/div/div[2]/a[1]\"\n",
    "            ).get_attribute(\"href\")  # Extract Twitter link\n",
    "    except:\n",
    "        p3_x = \"\"\n",
    "    try:\n",
    "        p3_linkedin = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/div/section/div[2]/div[3]/div[2]/div/div/div[2]/a[2]\"\n",
    "            ).get_attribute(\"href\")  # Extract LinkedIn link\n",
    "    except:\n",
    "        p3_linkedin = \"\"\n",
    "\n",
    "    # Extract details for Person 4 (P4)\n",
    "    try:\n",
    "        p4_name = driver.find_element(By.XPATH, \n",
    "            \"/html/body/div[1]/div[2]/section/div[2]/div[2]/div[3]/div[1]/div/div/div[1]\").text\n",
    "    except:\n",
    "        p4_name = \"\"\n",
    "    try:\n",
    "        p4_linkedin = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/section/div[2]/div[2]/div[3]/div[1]/div/div/div[3]/a\"\n",
    "            ).get_attribute(\"href\")  # Extract LinkedIn link\n",
    "    except:\n",
    "        p4_linkedin = \"\"\n",
    "\n",
    "    # Extract details for Person 5 (P5)\n",
    "    try:\n",
    "        p5_name = driver.find_element(By.XPATH, \n",
    "            \"/html/body/div[1]/div[2]/section/div[2]/div[2]/div[3]/div[2]/div/div/div[1]\").text\n",
    "    except:\n",
    "        p5_name = \"\"\n",
    "    try:\n",
    "        p5_linkedin = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[1]/div[2]/section/div[2]/div[2]/div[3]/div[2]/div/div/div[3]/a\"\n",
    "            ).get_attribute(\"href\")  # Extract LinkedIn link\n",
    "    except:\n",
    "        p5_linkedin = \"\"\n",
    "\n",
    "    # Store extracted data into a dictionary\n",
    "    profile_links = {\n",
    "        \"Company_name\": company_name,\n",
    "        \"P1_name\": p1_name,\n",
    "        \"P1_twitter\": p1_x,\n",
    "        \"P1_Linkedin\": p1_linkedin,\n",
    "        \"P2_name\": p2_name,\n",
    "        \"P2_twitter\": p2_x,\n",
    "        \"P2_Linkedin\": p2_linkedin,\n",
    "        \"P3_name\": p3_name,\n",
    "        \"P3_twitter\": p3_x,\n",
    "        \"P3_Linkedin\": p3_linkedin,\n",
    "        \"P4_name\": p4_name,\n",
    "        \"P4_Linkedin\": p4_linkedin,\n",
    "        \"P5_name\": p5_name,\n",
    "        \"P5_Linkedin\": p5_linkedin,\n",
    "    }\n",
    "\n",
    "    # Append the data to the main list\n",
    "    all_profile_data.append(profile_links)\n",
    "    print(f\"Scrape done for {len(all_profile_data)} companies\")  # Print progress\n",
    "\n",
    "# Save all data to an Excel file\n",
    "df = pd.DataFrame(all_profile_data)\n",
    "df.to_excel(\"ycombinator_founder_linkedin_complete.xlsx\", index=False)  # Save data without an index\n",
    "\n",
    "# Quit the WebDriver to close the browser session\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
